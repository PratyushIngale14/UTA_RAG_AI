{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        },
        "id": "csrSoAaxkcEW",
        "outputId": "f36346d7-26f8-4e6b-da65-540182335fca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index 'uta-rag' already exists. Skipping creation.\n",
            "Loading and splitting document: /content/PM_TEXTBOOK.pdf...\n",
            "Total chunks created: 2356\n",
            "Generating and uploading Gemini embeddings. This may take a few minutes...\n",
            "Upserted batch ending at chunk 50/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 100/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 150/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 200/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 250/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 300/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 350/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 400/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 450/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 500/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 550/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 600/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 650/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 700/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 750/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 800/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 850/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 900/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 950/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 1000/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 1050/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 1100/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 1150/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 1200/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 1250/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 1300/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 1350/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 1400/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 1450/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 1500/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 1550/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 1600/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 1650/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 1700/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 1750/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 1800/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 1850/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 1900/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 1950/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 2000/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 2050/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 2100/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 2150/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 2200/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 2250/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 2300/2356. Waiting 1 second...\n",
            "Upserted batch ending at chunk 2350/2356. Waiting 1 second...\n",
            "Upserted final batch.\n",
            "\n",
            " Indexing Complete! The university knowledge base is ready.\n"
          ]
        }
      ],
      "source": [
        "# ====================================================================\n",
        "# PHASE 1: DATA INDEXING (Run This in Google Colab)\n",
        "# ====================================================================\n",
        "\n",
        "# Cell 1: Installation and Setup\n",
        "# --------------------------------------------------------------------\n",
        "# Install the necessary libraries\n",
        "!pip install -q \\\n",
        "    google-genai \\\n",
        "    langchain \\\n",
        "    langchain-google-genai \\\n",
        "    pinecone-client \\\n",
        "    langchain-pinecone \\\n",
        "    pypdf \\\n",
        "    langchain-community \\\n",
        "    langchain-core \\\n",
        "    langchain-text-splitters --upgrade\n",
        "\n",
        "import os\n",
        "import uuid\n",
        "import time\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "# FINAL FIX: Use the specific recommended configuration module path\n",
        "from google.generativeai import configure, embed_content\n",
        "\n",
        "# --- 2. Configuration (Input your keys here) ---\n",
        "# NOTE: Replace with YOUR actual, full API key values.\n",
        "GEMINI_API_KEY = \"AIzaSyADC-p5kFNCJF68koiI6IlBUCq0qXGKX0k\"\n",
        "PINECONE_API_KEY = \"pcsk_4e9Swh_GgW9bEgEgiLjEqWMqo79wqYQmVQkcp9jrLCE52m9bHn1JbDGZAKpaf3kus4XB3\"\n",
        "\n",
        "# Index configuration using your confirmed values\n",
        "INDEX_NAME = \"uta-rag\"\n",
        "DIMENSION = 768\n",
        "CLOUD = \"aws\"\n",
        "REGION = \"us-east-1\"\n",
        "\n",
        "# Set environment variables (Crucial for system-wide access)\n",
        "os.environ['GEMINI_API_KEY'] = GEMINI_API_KEY\n",
        "os.environ['PINECONE_API_KEY'] = PINECONE_API_KEY\n",
        "\n",
        "# Configure native Gemini client (The guaranteed correct way)\n",
        "configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "\n",
        "# Cell 2: Index Creation\n",
        "# --------------------------------------------------------------------\n",
        "# --- A. Upload Document Path ---\n",
        "PDF_PATH = \"/content/PM_TEXTBOOK.pdf\"\n",
        "if not os.path.exists(PDF_PATH):\n",
        "    print(f\"Error: Please upload your university PDF named '{PDF_PATH}' to Colab.\")\n",
        "    raise FileNotFoundError\n",
        "\n",
        "# --- B. Initialize Pinecone and Create the Index (BYOV Configuration) ---\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "\n",
        "# Initialize Embeddings object (Passing key directly for stable authentication)\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\", api_key=GEMINI_API_KEY)\n",
        "\n",
        "if INDEX_NAME not in pc.list_indexes().names():\n",
        "    print(f\"Creating Bring Your Own Vectors (BYOV) index '{INDEX_NAME}'...\")\n",
        "    pc.create_index(\n",
        "        name=INDEX_NAME,\n",
        "        dimension=DIMENSION,\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(\n",
        "            cloud=CLOUD,\n",
        "            region=REGION\n",
        "        )\n",
        "    )\n",
        "    print(\"Index creation request sent. Waiting for index to be active...\")\n",
        "else:\n",
        "    print(f\"Index '{INDEX_NAME}' already exists. Skipping creation.\")\n",
        "\n",
        "\n",
        "# Cell 3: Load, Split, Embed, and Upload Data (The Working Solution)\n",
        "# --------------------------------------------------------------------\n",
        "# Define a function to get embeddings using the NATIVE Google GenAI client\n",
        "def get_native_embedding(text_content):\n",
        "    \"\"\"Generates an embedding vector using the authenticated native Gemini client.\"\"\"\n",
        "    # We now use the globally imported embed_content function\n",
        "    result = embed_content(\n",
        "        model=\"models/text-embedding-004\",\n",
        "        content=text_content,\n",
        "        task_type=\"RETRIEVAL_DOCUMENT\"\n",
        "    )\n",
        "    return result['embedding']\n",
        "\n",
        "print(f\"Loading and splitting document: {PDF_PATH}...\")\n",
        "loader = PyPDFLoader(PDF_PATH)\n",
        "documents = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=150\n",
        ")\n",
        "docs = text_splitter.split_documents(documents)\n",
        "print(f\"Total chunks created: {len(docs)}\")\n",
        "\n",
        "# --- 3. Generate Embeddings and Upsert ---\n",
        "index = pc.Index(INDEX_NAME)\n",
        "\n",
        "print(\"Generating and uploading Gemini embeddings. This may take a few minutes...\")\n",
        "\n",
        "vectors_to_upsert = []\n",
        "batch_size = 50\n",
        "total_chunks = len(docs)\n",
        "\n",
        "for i, doc in enumerate(docs):\n",
        "    text_content = doc.page_content\n",
        "    metadata = doc.metadata.copy()\n",
        "\n",
        "    # 3a. Call native Gemini client for the vector\n",
        "    try:\n",
        "        vector = get_native_embedding(text_content)\n",
        "    except Exception as e:\n",
        "        print(f\"Skipping chunk {i} due to embedding error: {e}\")\n",
        "        continue\n",
        "\n",
        "    # 3b. Prepare data for upsert\n",
        "    doc_id = str(uuid.uuid4())\n",
        "    metadata['text'] = text_content\n",
        "\n",
        "    vectors_to_upsert.append((doc_id, vector, metadata))\n",
        "\n",
        "    # 4. Upsert in Batches\n",
        "    if len(vectors_to_upsert) >= batch_size:\n",
        "        index.upsert(vectors=vectors_to_upsert, namespace=\"default\")\n",
        "        print(f\"Upserted batch ending at chunk {i+1}/{total_chunks}. Waiting 1 second...\")\n",
        "        vectors_to_upsert = []\n",
        "        time.sleep(1)\n",
        "\n",
        "# Upsert any remaining vectors\n",
        "if vectors_to_upsert:\n",
        "    index.upsert(vectors=vectors_to_upsert, namespace=\"default\")\n",
        "    print(f\"Upserted final batch.\")\n",
        "\n",
        "print(\"\\n Indexing Complete! The university knowledge base is ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bo97Rzv0v8sD"
      },
      "execution_count": 1,
      "outputs": []
    }
  ]
}